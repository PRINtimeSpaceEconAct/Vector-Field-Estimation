density_county$x
View(density_df_county)
logLightKm2_county_USA
range_state
density_df_county <- data.frame(x = density_county$x, y = density_county$y) %>% filter(x <= range_state[1] & x<= max(range_state))
# density
density_county <- density(logLightKm2_county_USA)
density_df_county <- data.frame(x = density_county$x, y = density_county$y) %>% filter(x <= range_state[1] & x<= max(range_state))
# filter(x >= -5 & x <= 8)
density_df_county$y <- 5*density_df_county$y   # scale height
density_cz <- density(logLightKm2_cz_USA)
density_df_cz <- data.frame(x = density_cz$x, y = density_cz$y) %>% filter(x >= -5 & x <= 8)
density_df_cz$y <- 5*density_df_cz$y   # scale height
density_state <- density(logLightKm2_state_USA)
density_df_state <- data.frame(x = density_state$x, y = density_state$y) %>% filter(x >= -5 & x <= 8)
density_df_state$y <- 5*density_df_state$y  # scale height
# density
density_county <- density(logLightKm2_county_USA)
density_df_county <- data.frame(x = density_county$x, y = density_county$y) %>% filter(x >= -5 & x <= 8)
density_df_county$y <- 5*density_df_county$y   # scale height
density_cz <- density(logLightKm2_cz_USA)
density_df_cz <- data.frame(x = density_cz$x, y = density_cz$y) %>% filter(x >= -5 & x <= 8)
density_df_cz$y <- 5*density_df_cz$y   # scale height
density_state <- density(logLightKm2_state_USA)
density_df_state <- data.frame(x = density_state$x, y = density_state$y) %>% filter(x <= range_state[1] & x<= max(range_state)) # filter(x >= -5 & x <= 8)
density_df_state$y <- 5*density_df_state$y  # scale height
dev.new()
ggplot(data_USA_plot, aes(x = range, y = quadraticEf, shape = model, color = model, group = aggregation)) +
geom_ribbon(aes(ymin = lowConf, ymax = highConf, fill = model), alpha = 0.2, linetype = 0) +  # Area ombreggiata per l'intervallo di confidenza
geom_point(size = 2, alpha = 0.8) +         # Punti più piccoli e trasparenti
geom_line(size = 0.5) +                     # Aumenta leggermente lo spessore delle linee
scale_shape_manual(values = c("COUNTY" = 4, "CZ" = 16, "STATE" = 18)) +
scale_color_manual(values = c("COUNTY" = "red4", "CZ" = "red3", "STATE"="red")) +
# scale_linetype_manual(values = c("COUNTY" = "dotted", "CZ" = "dashed", "STATE" = "solid")) +
labs(x = "", y = "Quadratic effect", title = "USA") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5),    # Titolo centrato
legend.title = element_blank(),            # Nessun titolo per le legende
legend.position = "right") +
geom_area(data = density_df_county, aes(x = x, y = y),
fill = "#fee6e4", color="red4", alpha = 0.4, inherit.aes = FALSE) +
geom_area(data = density_df_cz, aes(x = x, y = y),
fill = "#e6efd6", color="red3", alpha = 0.4, inherit.aes = FALSE) +
geom_area(data = density_df_state, aes(x = x, y = y),
fill = "#d9f3f3", color="red", alpha = 0.4, inherit.aes = FALSE)
density(logLightKm2_county_USA)
density_county
# density
density_county <- density(logLightKm2_county_USA)
density_county
data.frame(x = density_county$x, y = density_county$y)
density_state <- density(logLightKm2_state_USA)
density_state
data.frame(x = density_state$x, y = density_state$y)
logLightKm2_state_USA
summary(logLightKm2_state_USA)
range_state = range_county[range_county>=round(min(logLightKm2_state_USA)) & range_county<=max(logLightKm2_state_USA)]
range_state
pred_state
View(data_USA)
# Clearing the workspace
rm(list = ls())
# Loading required libraries
library(tidyr)
library(dplyr)
library(broom)
library(ggplot2)
library(stargazer)
library(plm)
library(fastDummies)
library(propagate)
## USA ----
load("nonlinearEstimation_USA.RData")
logLightKm2_county_USA = df_county$logLightKm2
logLightKm2_cz_USA = df_cz$logLightKm2
logLightKm2_state_USA = df_state$logLightKm2
range_county = seq(-5,8,by=0.4)
range_cz = range_county[range_county>=min(logLightKm2_cz_USA) & range_county<=max(logLightKm2_cz_USA)]
range_state = range_county[range_county>=round(min(logLightKm2_state_USA)) & range_county<=max(logLightKm2_state_USA)]
data_USA = data.frame(range_county= range_county,
range_cz=ifelse(range_county>=min(logLightKm2_cz_USA) & range_county<=max(logLightKm2_cz_USA), range_county, NA),
range_state=ifelse(range_county>=min(logLightKm2_state_USA) & range_county<=max(logLightKm2_state_USA), range_county, NA))
View(data_USA)
logLightKm2_county_USA
logLightKm2_cz_USA
length(logLightKm2_county_USA)
length(logLightKm2_cz_USA)
length(logLightKm2_state_USA)
summary(logLightKm2_county_USA)
summary(logLightKm2_cz_USA)
summary(logLightKm2_state_USA)
range_state=ifelse(range_county>=round(min(logLightKm2_state_USA) & range_county<=max(logLightKm2_state_USA), range_county, NA))
data_USA = data.frame(range_county= range_county,
range_cz=ifelse(range_county>=min(logLightKm2_cz_USA) & range_county<=max(logLightKm2_cz_USA), range_county, NA),
range_state=ifelse(range_county>=round(min(logLightKm2_state_USA)) & range_county<=max(logLightKm2_state_USA), range_county, NA))
data_USA_county = data.frame(logLightKm2=data_USA$range_county, areaKm2=1, time_2013=0, time_2014=0, time_2015=0, time_2016=0, time_2017=0, time_2018=0, time_2019=0)
data_USA_cz = data.frame(logLightKm2=data_USA$range_county, areaKm2=1, time_2013=0, time_2014=0, time_2015=0, time_2016=0, time_2017=0, time_2018=0, time_2019=0) %>% na.omit()
data_USA_state = data.frame(logLightKm2=data_USA$range_state, areaKm2=1, time_2013=0, time_2014=0, time_2015=0, time_2016=0, time_2017=0, time_2018=0, time_2019=0) %>% na.omit()
pred_state = predictNLS(lmStateNLS, newdata = data_USA_state, interval = "confidence")
pred_state = pred_state$summary
save(pred_county, pred_cz, pred_state, file="pred_USA.RData")
pred_county = pred_county$summary
ls()
pred_state
load("nonlinearEstimation_USA.RData")
logLightKm2_county_USA = df_county$logLightKm2
logLightKm2_cz_USA = df_cz$logLightKm2
logLightKm2_state_USA = df_state$logLightKm2
range_county = seq(-5,8,by=0.4)
range_cz = range_county[range_county>=min(logLightKm2_cz_USA) & range_county<=max(logLightKm2_cz_USA)]
range_state = range_county[range_county>=round(min(logLightKm2_state_USA)) & range_county<=max(logLightKm2_state_USA)]
data_USA = data.frame(range_county= range_county,
range_cz=ifelse(range_county>=min(logLightKm2_cz_USA) & range_county<=max(logLightKm2_cz_USA), range_county, NA),
range_state=ifelse(range_county>=round(min(logLightKm2_state_USA)) & range_county<=max(logLightKm2_state_USA), range_county, NA))
data_USA_county = data.frame(logLightKm2=data_USA$range_county, areaKm2=1, time_2013=0, time_2014=0, time_2015=0, time_2016=0, time_2017=0, time_2018=0, time_2019=0)
pred_county = predictNLS(lmCountyNLS, newdata = data_USA_county, interval = "confidence")
data_USA_cz = data.frame(logLightKm2=data_USA$range_county, areaKm2=1, time_2013=0, time_2014=0, time_2015=0, time_2016=0, time_2017=0, time_2018=0, time_2019=0) %>% na.omit()
pred_cz = predictNLS(lmCZNLS, newdata = data_USA_cz, interval = "confidence")
data_USA_state = data.frame(logLightKm2=data_USA$range_state, areaKm2=1, time_2013=0, time_2014=0, time_2015=0, time_2016=0, time_2017=0, time_2018=0, time_2019=0) %>% na.omit()
pred_state = predictNLS(lmStateNLS, newdata = data_USA_state, interval = "confidence")
pred_county = pred_county$summary
pred_cz = pred_cz$summary
pred_state = pred_state$summary
save(pred_county, pred_cz, pred_state, file="pred_USA.RData")
data_USA$logRealIncomeKm2_county[!is.na(data_USA$range_county)] = pred_county[,1]
data_USA$logRealIncomeKm2_cz[!is.na(data_USA$range_county)] = pred_cz[,1]
data_USA$logRealIncomeKm2_state[!is.na(data_USA$range_state)] = pred_state[,1]
data_USA$lowConf_county[!is.na(data_USA$range_county)] = pred_county[,5]
data_USA$lowConf_cz[!is.na(data_USA$range_county)] = pred_cz[,5]
data_USA$lowConf_state[!is.na(data_USA$range_state)] = pred_state[,5]
data_USA$highConf_county[!is.na(data_USA$range_county)] = pred_county[,6]
data_USA$highConf_cz[!is.na(data_USA$range_county)] = pred_cz[,6]
data_USA$highConf_state[!is.na(data_USA$range_state)] = pred_state[,6]
#Remove outlier (lower than -5)
data_USA = data_USA %>% filter(range_county> -5)
data_USA_plot = tibble(range=c(data_USA$range_county,data_USA$range_county, data_USA$range_state),
quadraticEf=c(data_USA$logRealIncomeKm2_county, data_USA$logRealIncomeKm2_cz, data_USA$logRealIncomeKm2_state),  lowConf=c(data_USA$lowConf_county, data_USA$lowConf_cz, data_USA$lowConf_state),
highConf=c(data_USA$highConf_county, data_USA$highConf_cz, data_USA$highConf_state),
model=c(rep("COUNTY", length(data_USA$range_county)), rep("CZ", length(data_USA$range_county)),
rep("STATE", length(data_USA$range_state))))
data_USA_plot = data_USA_plot %>% mutate(aggregation=ifelse(model=="MUN" | model=="COUNTY", "1",
ifelse(model=="LLA" | model=="MICRO" |model=="CZ", "2",
ifelse(model=="meso" | model=="MESO" |model=="STATE", "3", "4"))))
data_USA_plot <- data_USA_plot %>%
mutate(model = factor(model, levels = unique(model[order(as.numeric(aggregation))])))
# density
density_county <- density(logLightKm2_county_USA)
density_df_county <- data.frame(x = density_county$x, y = density_county$y) %>% filter(x >= -5 & x <= 8)
density_df_county$y <- 5*density_df_county$y   # scale height
density_cz <- density(logLightKm2_cz_USA)
density_df_cz <- data.frame(x = density_cz$x, y = density_cz$y) %>% filter(x >= -5 & x <= 8)
density_df_cz$y <- 5*density_df_cz$y   # scale height
density_state <- density(logLightKm2_state_USA)
density_df_state <- data.frame(x = density_state$x, y = density_state$y) %>% filter(x <= range_state[1] & x<= max(range_state)) # filter(x >= -5 & x <= 8)
density_df_state$y <- 5*density_df_state$y  # scale height
dev.new()
ggplot(data_USA_plot, aes(x = range, y = quadraticEf, shape = model, color = model, group = aggregation)) +
geom_ribbon(aes(ymin = lowConf, ymax = highConf, fill = model), alpha = 0.2, linetype = 0) +  # Area ombreggiata per l'intervallo di confidenza
geom_point(size = 2, alpha = 0.8) +         # Punti più piccoli e trasparenti
geom_line(size = 0.5) +                     # Aumenta leggermente lo spessore delle linee
scale_shape_manual(values = c("COUNTY" = 4, "CZ" = 16, "STATE" = 18)) +
scale_color_manual(values = c("COUNTY" = "red4", "CZ" = "red3", "STATE"="red")) +
# scale_linetype_manual(values = c("COUNTY" = "dotted", "CZ" = "dashed", "STATE" = "solid")) +
labs(x = "", y = "Quadratic effect", title = "USA") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5),    # Titolo centrato
legend.title = element_blank(),            # Nessun titolo per le legende
legend.position = "right") +
geom_area(data = density_df_county, aes(x = x, y = y),
fill = "#fee6e4", color="red4", alpha = 0.4, inherit.aes = FALSE) +
geom_area(data = density_df_cz, aes(x = x, y = y),
fill = "#e6efd6", color="red3", alpha = 0.4, inherit.aes = FALSE) +
geom_area(data = density_df_state, aes(x = x, y = y),
fill = "#d9f3f3", color="red", alpha = 0.4, inherit.aes = FALSE)
density_df_state <- data.frame(x = density_state$x, y = density_state$y) %>% filter(x >= -5 & x <= 8)
density_df_state$y <- 5*density_df_state$y  # scale height
density_state <- density(logLightKm2_state_USA)
density_df_state <- data.frame(x = density_state$x, y = density_state$y) %>% filter(x >= -5 & x <= 8)
density_df_state$y <- 5*density_df_state$y  # scale height
dev.new()
ggplot(data_USA_plot, aes(x = range, y = quadraticEf, shape = model, color = model, group = aggregation)) +
geom_ribbon(aes(ymin = lowConf, ymax = highConf, fill = model), alpha = 0.2, linetype = 0) +  # Area ombreggiata per l'intervallo di confidenza
geom_point(size = 2, alpha = 0.8) +         # Punti più piccoli e trasparenti
geom_line(size = 0.5) +                     # Aumenta leggermente lo spessore delle linee
scale_shape_manual(values = c("COUNTY" = 4, "CZ" = 16, "STATE" = 18)) +
scale_color_manual(values = c("COUNTY" = "red4", "CZ" = "red3", "STATE"="red")) +
# scale_linetype_manual(values = c("COUNTY" = "dotted", "CZ" = "dashed", "STATE" = "solid")) +
labs(x = "", y = "Quadratic effect", title = "USA") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5),    # Titolo centrato
legend.title = element_blank(),            # Nessun titolo per le legende
legend.position = "right") +
geom_area(data = density_df_county, aes(x = x, y = y),
fill = "#fee6e4", color="red4", alpha = 0.4, inherit.aes = FALSE) +
geom_area(data = density_df_cz, aes(x = x, y = y),
fill = "#e6efd6", color="red3", alpha = 0.4, inherit.aes = FALSE) +
geom_area(data = density_df_state, aes(x = x, y = y),
fill = "#d9f3f3", color="red", alpha = 0.4, inherit.aes = FALSE)
View(data_USA_plot)
dev.new()
ggplot(data_USA_plot, aes(x = range, y = quadraticEf, shape = model, color = model, group = aggregation)) +
geom_ribbon(aes(ymin = lowConf, ymax = highConf, fill = model), alpha = 0.2, linetype = 0) +  # Area ombreggiata per l'intervallo di confidenza
geom_point(size = 2, alpha = 0.8) +         # Punti più piccoli e trasparenti
geom_line(size = 0.5) +                     # Aumenta leggermente lo spessore delle linee
scale_shape_manual(values = c("COUNTY" = 4, "CZ" = 16, "STATE" = 18)) +
scale_color_manual(values = c("COUNTY" = "red4", "CZ" = "red3", "STATE"="red")) +
# scale_linetype_manual(values = c("COUNTY" = "dotted", "CZ" = "dashed", "STATE" = "solid")) +
labs(x = "", y = "Quadratic effect", title = "USA") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5),    # Titolo centrato
legend.title = element_blank(),            # Nessun titolo per le legende
legend.position = "right") +
geom_area(data = density_df_county, aes(x = x, y = y),
fill = "#fee6e4", color="red4", alpha = 0.4, inherit.aes = FALSE) +
geom_area(data = density_df_cz, aes(x = x, y = y),
fill = "#e6efd6", color="red3", alpha = 0.4, inherit.aes = FALSE) +
geom_area(data = density_df_state, aes(x = x, y = y),
fill = "#d9f3f3", color="red", alpha = 0.4, inherit.aes = FALSE)
ggsave(filename = "EstimatedNonlinearEffect_USA.pdf")
# Clearing the workspace
rm(list = ls())
# Loading required libraries
library(tidyr)
library(dplyr)
library(broom)
library(ggplot2)
library(stargazer)
library(plm)
library(fastDummies)
library(propagate)
load("beta_IT_income.RData")
load("beta_BRA_income.RData")
load("beta_USA_income.RData")
load("alpha_IT_income.RData")
load("alpha_BRA_income.RData")
load("alpha_USA_income.RData")
##Italy ----
load("nonlinearEstimation_ITA.RData")
logLightKm2_mun_ITA = df_munic$logLightKm2
logLightKm2_sll_ITA = df_SLL$logLightKm2
logLightKm2_nuts3_ITA = df_NUTS3$logLightKm2
logLightKm2_nuts2_ITA = df_NUTS2$logLightKm2
## USA ----
load("nonlinearEstimation_USA.RData")
logLightKm2_county_USA = df_county$logLightKm2
logLightKm2_cz_USA = df_cz$logLightKm2
logLightKm2_state_USA = df_state$logLightKm2
logLightKm2_county_USA = df_county$logLightKm2
logLightKm2_cz_USA = df_cz$logLightKm2
logLightKm2_state_USA = df_state$logLightKm2
summary(logLightKm2_state_USA)
range_county = seq(-5,8,by=0.4)
range_cz = range_county[range_county>=min(logLightKm2_cz_USA) & range_county<=max(logLightKm2_cz_USA)]
# range_state = range_county[range_county>=round(min(logLightKm2_state_USA)) & range_county<=max(logLightKm2_state_USA)]
range_state = range_county[range_county>=(min(logLightKm2_state_USA)) & range_county<=max(logLightKm2_state_USA)]
range_state
data_USA = data.frame(range_county= range_county,
range_cz=ifelse(range_county>=min(logLightKm2_cz_USA) & range_county<=max(logLightKm2_cz_USA), range_county, NA),
range_state=ifelse(range_county>=round(min(logLightKm2_state_USA)) & range_county<=max(logLightKm2_state_USA), range_county, NA))
View(data_USA)
# Clear workspace and load dependencies
setwd("~/Library/CloudStorage/OneDrive-UniversityofPisa/timeSpaceEvolutionEcAct/RVF/R code/Vector Field Estimation/")
rm(list = ls())
DEBUG = TRUE
source("src/libs/loadLib.R")
library(fields)
library(latex2exp)
# parameters ----
nObs = 1000
nEval = 2500
# data Generation ----
set.seed(1)
X0 = mvrnorm(nObs, mu=c(0,0),Sigma = 0.5*diag(2))
# example 1 - double well ----
VF <- function(X){
# X = (x,y)
# U(X) = x^4 - x^2 + y^2
# VF(X) = -grad U(X) = -(4x^3 - 2x, 2y)
return( -0.1*c(4*X[1]^3 - 2*X[1], 2*X[2]) )
}
# example 2 -- single well ----
# VF <- function(X){
#     # X = (x,y)
#     # U(X) = x^2 + y^2
#     # VF(X) = -grad U(X) = -(2x, 2y)
#     return( -0.01*c(2*X[1], 2*X[2]) )
# }
# example 3 -- rotation ----
# M = matrix(c(cos(pi/2), -sin(pi/2), sin(pi/2), cos(pi/2)),nrow=2,ncol=2)
# VF <- function(X){
#     # X = (x,y), theta = pi/4
#     return (M %*% X)
# }
# apply VF
X1 = X0 + t(apply(X0, 1, VF)) +  matrix(rnorm(2*nObs),nrow=nObs) %*% matrix(c(0.01,0.005,0.005,0.02),nrow=2)
# eval points
xGrid = seq(from=-1, to=1, length.out=round(sqrt(nEval)))
yGrid = seq(from=-1, to=1, length.out=round(sqrt(nEval)))
# xGrid = seq(from=min(c(X0[,1],X1[,1])), to=max(c(X0[,1],X1[,1])), length.out=round(sqrt(nEval)))
# yGrid = seq(from=min(c(X0[,2],X1[,2])), to=max(c(X0[,2],X1[,2])), length.out=round(sqrt(nEval)))
x = as.matrix(expand.grid(xGrid, yGrid))
# stima ----
t0 = Sys.time()
est_field_adaptive = LLfieldAdaptive(X0, X1, x=x, kernel.type="epa",method.h = "silverman",
chunk_size=3000,
sparse=FALSE, gc=TRUE, hOpt = TRUE, alphaOpt = TRUE)
est_field_adaptive
est_field_adaptive = bootstrapKernelFieldErrors(est_field_adaptive)
DEBUG = FALSE
est_field_adaptive = bootstrapKernelFieldErrors(est_field_adaptive)
est_field_adaptive = bootstrapKernelFieldErrors(est_field_adaptive, B = 10)
est_field_adaptive_bootstrap = bootstrapKernelFieldErrors(est_field_adaptive, B = 10)
est_field_adaptive_bootstrap
class(est_field_adaptive_bootstrap)
dim(est_field_adaptive_bootstrap)
bootstrap
est_field_adaptive$estimator
dim(est_field_adaptive$estimator)
is.nan()
result=est_field_adaptive
#Where we can calculate a directional vectors: both different from zero and both different from NaN
where.est.directions <- (result$estimator[,1]!=0 & result$estimator[,2]!=0) & (!is.nan(result$estimator[,1]) & !is.nan(result$estimator[,2]))
where.est.directions
#Where we can calculate a directional vectors: both different from zero and both different from NaN
where.est <- (result$estimator[,1]!=0 & result$estimator[,2]!=0) & (!is.nan(result$estimator[,1]) & !is.nan(result$estimator[,2]))
bootstrapSamples=est_field_adaptive_bootstrap
dim(bootstrapSamples)
estConfInt <- vector("numeric", length = nrow(result$x))
estConfInt <- matrix(NA, nrow = nrow(result$x), ncol=2)
nEval = nrow(result$x)
nBoot = dim(bootstrapSamples)[3]
nBoot
mean(c(1,1,NA))
mean(c(1,1,NA),na.rm=T)
mean(c(1,1,NaN),na.rm=T)
mean(c(1,1,NaN,3),na.rm=T)
bootstrapSamples[j,1,]
j = 1
j = 1250
max(mean(bootstrapSamples[j,1,]<0,na.rm=T),mean(bootstrapSamples[j,1,]>0,na.rm=T))
mean(bootstrapSamples[j,1,]<0,na.rm=T)
mean(bootstrapSamples[j,1,]>0,na.rm=T)
j = 1000
max(mean(bootstrapSamples[j,1,]<0,na.rm=T),mean(bootstrapSamples[j,1,]>0,na.rm=T))
for (j in 1:nEval){
estConfInt[j,1] =  max(mean(bootstrapSamples[j,1,]<0,na.rm=T),mean(bootstrapSamples[j,1,]>0,na.rm=T))
estConfInt[j,2] =  max(mean(bootstrapSamples[j,2,]<0,na.rm=T),mean(bootstrapSamples[j,2,]>0,na.rm=T))
}
estConfInt
#Where we can calculate a directional vectors: both different from zero and both different from NaN
where.est = (result$estimator[,1]!=0 & result$estimator[,2]!=0) & (!is.nan(result$estimator[,1]) & !is.nan(result$estimator[,2]))
where.est
?find()
find(where.est)
apropos(where.est)
which(where.est)
#Where we can calculate a directional vectors: both different from zero and both different from NaN
whereEst = (result$estimator[,1]!=0 & result$estimator[,2]!=0) & (!is.nan(result$estimator[,1]) & !is.nan(result$estimator[,2]))
whereEstInd = which(whereEstInd)
#Where we can calculate a directional vectors: both different from zero and both different from NaN
whereEst = (result$estimator[,1]!=0 & result$estimator[,2]!=0) & (!is.nan(result$estimator[,1]) & !is.nan(result$estimator[,2]))
whereEstInd = which(whereEstInd)
whereEstInd = which(whereEst)
estConfInt<(1-p_crit)
p_crit=0.05
estConfInt<(1-p_crit)
estConfInt>(1-p_crit)
colSums(estConfInt>(1-p_crit))
rowSums(estConfInt>(1-p_crit))
rowSums(estConfInt>(1-p_crit))==ncol(result$x)
ncol(result$x)
estConfInt = matrix(FALSE, nrow=nEval, ncol=2)
for (j in whereEstInd){
estConfInt[j,1] =  max(mean(bootstrapSamples[j,1,]<0,na.rm=T),mean(bootstrapSamples[j,1,]>0,na.rm=T))
estConfInt[j,2] =  max(mean(bootstrapSamples[j,2,]<0,na.rm=T),mean(bootstrapSamples[j,2,]>0,na.rm=T))
}
rowSums(estConfInt>(1-p_crit))==ncol(result$x)
rowSums(estConfInt>(1-p_crit))
nEval = nrow(result$x)
nBoot = dim(bootstrapSamples)[3]
estConfInt = matrix(NA, nrow=nEval, ncol=2)
for (j in whereEstInd){
estConfInt[j,1] =  max(mean(bootstrapSamples[j,1,]<0,na.rm=T),mean(bootstrapSamples[j,1,]>0,na.rm=T))
estConfInt[j,2] =  max(mean(bootstrapSamples[j,2,]<0,na.rm=T),mean(bootstrapSamples[j,2,]>0,na.rm=T))
}
estConfInt[is.na(estConfInt)] = FALSE
estConfInt
estConfInt
whereEst = (result$estimator[,1]!=0 & result$estimator[,2]!=0) & (!is.nan(result$estimator[,1]) & !is.nan(result$estimator[,2]))
whereEstInd = which(whereEst)
nEval = nrow(result$x)
nBoot = dim(bootstrapSamples)[3]
estConfInt = matrix(NA, nrow=nEval, ncol=2)
for (j in whereEstInd){
estConfInt[j,1] =  max(mean(bootstrapSamples[j,1,]<0,na.rm=T),mean(bootstrapSamples[j,1,]>0,na.rm=T))
estConfInt[j,2] =  max(mean(bootstrapSamples[j,2,]<0,na.rm=T),mean(bootstrapSamples[j,2,]>0,na.rm=T))
}
estConfInt
rowSums(estConfInt>(1-p_crit))==ncol(result$x)
estConfInt[is.na(estConfInt)] = FALSE
rowSums(estConfInt>(1-p_crit))==ncol(result$x)
signifEst = rowSums(estConfInt>(1-p_crit))==ncol(result$x)
sapply(whereEstInd, x -> function(x) max(mean(bootstrapSamples[x,1,]<0,na.rm=T),mean(bootstrapSamples[x,1,]>0,na.rm=T)))
sapply(whereEstInd, x -> function(x) {max(mean(bootstrapSamples[x,1,]<0,na.rm=T),mean(bootstrapSamples[x,1,]>0,na.rm=T))})
j = 1
sapply(whereEstInd, function(x) max(mean(bootstrapSamples[x,1,]<0,na.rm=T),mean(bootstrapSamples[x,1,]>0,na.rm=T)) )
nEval = nrow(result$x)
estConfInt = matrix(NA, nrow=nEval, ncol=2)
#Where we can calculate a directional vectors: both different from zero and both different from NaN
whereEst = (result$estimator[,1]!=0 & result$estimator[,2]!=0) & (!is.nan(result$estimator[,1]) & !is.nan(result$estimator[,2]))
whereEstInd = which(whereEst)
estConfInt2 = estConfInt
estConfInt2[,1] = sapply(whereEstInd, function(i) max(mean(bootstrapSamples[i,1,]<0,na.rm=T),mean(bootstrapSamples[i,1,]>0,na.rm=T)) )
estConfInt2 = estConfInt
sapply(whereEstInd, function(i) max(mean(bootstrapSamples[i,1,]<0,na.rm=T),mean(bootstrapSamples[i,1,]>0,na.rm=T)) )
estConfInt2
nEval = nrow(result$x)
estConfInt = matrix(NA, nrow=nEval, ncol=2)
#Where we can calculate a directional vectors: both different from zero and both different from NaN
whereEst = (result$estimator[,1]!=0 & result$estimator[,2]!=0) & (!is.nan(result$estimator[,1]) & !is.nan(result$estimator[,2]))
whereEstInd = which(whereEst)
estConfInt2 = estConfInt
estConfInt2[whereEstInd,1] = sapply(whereEstInd, function(i) max(mean(bootstrapSamples[i,1,]<0,na.rm=T),mean(bootstrapSamples[i,1,]>0,na.rm=T)) )
estConfInt2[whereEstInd,2] = sapply(whereEstInd, function(i) max(mean(bootstrapSamples[i,2,]<0,na.rm=T),mean(bootstrapSamples[i,2,]>0,na.rm=T)) )
for (j in whereEstInd){
estConfInt[j,1] =  max(mean(bootstrapSamples[j,1,]<0,na.rm=T),mean(bootstrapSamples[j,1,]>0,na.rm=T))
estConfInt[j,2] =  max(mean(bootstrapSamples[j,2,]<0,na.rm=T),mean(bootstrapSamples[j,2,]>0,na.rm=T))
}
estConfInt2 - estConfInt
estConfInt2[whereEstInd,] - estConfInt[whereEstInd,]
summary(estConfInt2[whereEstInd,] - estConfInt[whereEstInd,])
estConfInt
estConfInt2
signifBoot = significanceBootstrap(est_field_adaptive,est_field_adaptive_bootstrap)
source("~/Library/CloudStorage/OneDrive-UniversityofPisa/timeSpaceEvolutionEcAct/RVF/R code/Vector Field Estimation/src/libs/Variance.R", echo=TRUE)
signifBoot = significanceBootstrap(est_field_adaptive,est_field_adaptive_bootstrap)
signifBoot
which(signifBoot)
dev.new()
op <- par(family = "mono") #Possible families: "mono", "Helvetica","Palatino" or "Times"
signifVFest = significanceVF(est_field_adaptive,X0,X1,0.01)
op <- par(family = "mono") #Possible families: "mono", "Helvetica","Palatino" or "Times"
signifVFest = significanceVF(est_field_adaptive)
lengthArrows=0.1
plot(x, type = "n", xlab = TeX(r'($X_1$)'), ylab=TeX(r'($X_2$)'), main = "")
arrows(est_field_adaptive$x[,1], est_field_adaptive$x[,2],
est_field_adaptive$x[,1] + lengthArrows*est_field_adaptive$estimator[,1],
est_field_adaptive$x[,2] + lengthArrows*est_field_adaptive$estimator[,2],
length = 0.05, angle = 15, col = "blue")
abline(h=0)
abline(v=0)
# dev.copy2pdf(file="testPics/doubleWellcampoStimato.pdf")
par(op)
op <- par(family = "mono") #Possible families: "mono", "Helvetica","Palatino" or "Times"
signifVFest = significanceVF(est_field_adaptive)
lengthArrows=0.1
plot(x, type = "n", xlab = TeX(r'($X_1$)'), ylab=TeX(r'($X_2$)'), main = "")
arrows(est_field_adaptive$x[,1], est_field_adaptive$x[,2],
est_field_adaptive$x[,1] + lengthArrows*est_field_adaptive$estimator[,1],
est_field_adaptive$x[,2] + lengthArrows*est_field_adaptive$estimator[,2],
length = 0.05, angle = 15, col = "blue")
abline(h=0)
abline(v=0)
# dev.copy2pdf(file="testPics/doubleWellcampoStimato.pdf")
par(op)
dev.new()
op <- par(family = "mono") #Possible families: "mono", "Helvetica","Palatino" or "Times"
signifVFest = significanceVF(est_field_adaptive)
lengthArrows=0.1
plot(x, type = "n", xlab = TeX(r'($X_1$)'), ylab=TeX(r'($X_2$)'), main = "")
arrows(est_field_adaptive$x[,1], est_field_adaptive$x[,2],
est_field_adaptive$x[,1] + lengthArrows*est_field_adaptive$estimator[,1],
est_field_adaptive$x[,2] + lengthArrows*est_field_adaptive$estimator[,2],
length = 0.05, angle = 15, col = "blue")
abline(h=0)
abline(v=0)
# dev.copy2pdf(file="testPics/doubleWellcampoStimato.pdf")
par(op)
est_field_adaptive = NWfieldAdaptive(X0, X1, x=x, kernel.type="gauss",method.h = "silverman",
chunk_size=1000,
sparse=FALSE, gc=TRUE, alpha=0.5,
hOpt = TRUE, alphaOpt = TRUE)
# bootstrap
est_field_adaptive_bootstrap = bootstrapKernelFieldErrors(est_field_adaptive, B = 10)
signifBoot = significanceBootstrap(est_field_adaptive,est_field_adaptive_bootstrap)
op <- par(family = "mono") #Possible families: "mono", "Helvetica","Palatino" or "Times"
signifVFest = significanceVF(est_field_adaptive)
lengthArrows=0.1
plot(x, type = "n", xlab = TeX(r'($X_1$)'), ylab=TeX(r'($X_2$)'), main = "")
arrows(est_field_adaptive$x[,1], est_field_adaptive$x[,2],
est_field_adaptive$x[,1] + lengthArrows*est_field_adaptive$estimator[,1],
est_field_adaptive$x[,2] + lengthArrows*est_field_adaptive$estimator[,2],
length = 0.05, angle = 15, col = "blue")
abline(h=0)
abline(v=0)
signifInd = which(signifBoot)
dev.new()
op <- par(family = "mono") #Possible families: "mono", "Helvetica","Palatino" or "Times"
signifVFest = significanceVF(est_field_adaptive,X0,X1,0.01)
op <- par(family = "mono") #Possible families: "mono", "Helvetica","Palatino" or "Times"
lengthArrows=0.1
plot(x, type = "n", xlab = TeX(r'($X_1$)'), ylab=TeX(r'($X_2$)'), main = "")
arrows(est_field_adaptive$x[signifInd,1], est_field_adaptive$x[signifInd,2],
est_field_adaptive$x[signifInd,1] + lengthArrows*est_field_adaptive$estimator[signifInd,1],
est_field_adaptive$x[signifInd,2] + lengthArrows*est_field_adaptive$estimator[signifInd,2],
length = 0.05, angle = 15, col = "blue")
abline(h=0)
abline(v=0)
