#' Core kernel method for density estimation and regression
#' 
#' @param X Matrix of input points (nObs x 2)
#' @param x Matrix of evaluation points (nEval x 2, if NULL, generated by defineEvalPoints)
#' @param nEval Number of evaluation points if x is NULL (default: 2500)
#' @param kernel.type Type of kernel function to use (default: "gauss")
#' @param D Pre-computed distance components (if NULL, computed internally)
#' @param method.h Method for bandwidth selection (if NULL, specified h is used)
#' @param h Bandwidth parameter (if NULL, selected by method.h)
#' @param lambda Vector of local bandwidths for adaptive estimation (nObs)
#' @param sparse Whether to use sparse matrices (default: FALSE)
#' @param gc Whether to force garbage collection (default: FALSE)
#' @param chunk_size Number of points to process at once (default: nrow(x))
#' @param type.est Type of estimation: "density", "NW", or "LL"
#' @param Y Vector of response values (nObs, required for regression methods)
#' 
#' @return A list containing the estimation results and parameters:
#'   \item{x}{Matrix of evaluation points (nEval x 2)}
#'   \item{estimator}{Vector or matrix of estimation results (nEval)}
#'   \item{density}{Vector of density estimates at evaluation points (nEval)}
#'   \item{h}{Bandwidth parameter used}
#'   \item{method.h}{Method used for bandwidth selection}
#'   \item{kernel.type}{Type of kernel function used}
#'   \item{Hkk_values}{Vector of hat matrix diagonal values (nObs, only for LL estimation)}
kernelMethod <- function(X, x=NULL, nEval=2500, kernel.type="gauss", D=NULL, 
                             method.h=NULL, h=NULL, lambda=NULL, 
                             sparse=FALSE, gc=FALSE, chunk_size=nrow(x), type.est=NULL, Y=NULL) {
    
    nObs = nrow(X)
    covX = cov(X)
    invS = solve(covX)
    sqrtinvS = expm::sqrtm(solve(covX))
    detS = det(covX)
    
    Z = X %*% sqrtinvS
    z = x %*% sqrtinvS
    
    if (is.null(x)) { x = defineEvalPoints(X,nEval) }
    nEval =  nrow(x)
    if (DEBUG) {
        print(paste("nEval: ",nEval))
        print(paste("nObs: ",nObs)) }
    if (is.null(chunk_size)) { chunk_size = nrow(x) }
    if (is.null(lambda)) { lambda = rep(1,nObs) }
    
    if (is.null(type.est)) { stop("type.est not specified") }
    if (is.null(h) | is.null(method.h)) { 
        list.h = define_h_method.h(Z,h,method.h, kernel.type)
        h = list.h$h
        method.h = list.h$method.h }
    kernelFunction = defineKernel(kernel.type)
    
    
    density = numeric(nEval)
    kernel_sum = numeric(nEval)
    estimator = numeric(nEval)


    chunks = split(seq_len(nEval), ceiling(seq_len(nEval)/chunk_size))
    
    # Start computing the trace of the H matrix needed for AICc if LL is used
    if (type.est == "LL") {
        # Pre-allocate the full vector for Hkk values
        Hkk_values = numeric(nEval) 
    }
    
    if (DEBUG) {
        print(paste("Computing ",length(chunks)," chunks"))
        print(paste("Chunk size: ",chunk_size)) }
    
    # start estimate
    for(i in 1:length(chunks)) {
        if (DEBUG) print(paste("Computing chunk ",i,"/",length(chunks),sep=""))
        
        chunk = chunks[[i]]
        z_chunk = z[chunk, ,drop=FALSE]
        
        if (is.null(D)){ D_chunk = computeDcomponents(Z, z_chunk, sparse=sparse) 
        } else { D_chunk = list(z1=D$z1[,chunk], z2=D$z2[,chunk]) }
        
        # Kernel computation
        K = kernelFunction(sweep(D_chunk$z1, 1, h * lambda, "/"),sweep(D_chunk$z2, 1, h * lambda, "/"))
        if (gc == TRUE){ gc() }
        
        K_scaled = sweep(K, 1, lambda^2, "/")
        
        # insert bootstrap here 
        
        # switch between density, NW
        switch(type.est,
               "density" = {
                   estimator[chunk] = computeTerms(D_chunk, Y, h, detS, K_scaled, type.est) 
                   density[chunk] = estimator[chunk]},
               "NW" = {
                   estimator[chunk] = computeTerms(D_chunk, Y, h, detS, K_scaled, type.est)
                   density[chunk] = computeTerms(D_chunk, Y, h, detS, K_scaled, "density")  },
               "LL" = {
                   # Pass kernelFunction, lambda vector, and chunk indices
                   LLoutputs = computeTerms(D_chunk, Y, h, detS, K_scaled, type.est) 
                   estimator[chunk] = LLoutputs$solutions
                   # Assign Hkk values directly using chunk indices
                   Hkk_values[chunk] = LLoutputs$Hkk_values_chunk
                   density[chunk] = computeTerms(D_chunk, Y, h, detS, K_scaled, "density")  },
               {
                   stop(paste("Invalid type.est:", type.est, ". Must be either 'density' or 'NW'."))
               }
        )
        if (gc == TRUE){ gc() }
    }
    if (type.est == "LL") {
        return(listN(x, estimator, density, h, method.h, kernel.type, Hkk_values))
    } else {
        return(listN(x, estimator, density, h, method.h, kernel.type))
    }
}


#' Computes terms for different kernel estimation methods
#' 
#' @param distances Distance components between input and evaluation points: 
#'        list with z1 and z2 matrices (nObs x nEval_chunk)
#' @param Y Vector of response values (nObs, for regression methods)
#' @param h Bandwidth parameter
#' @param detS Determinant of covariance matrix
#' @param K_scaled Matrix of scaled kernel weights (nObs x nEval_chunk)
#' @param type.est Type of estimation: "density", "NW", or "LL"
#' 
#' @return For "density": Vector of density values (nEval_chunk)
#'         For "NW": Vector of regression estimates (nEval_chunk)
#'         For "LL": List of solutions (nEval_chunk) and Hkk_values_chunk (nEval_chunk)
computeTerms <- function(distances, Y, h, detS, K_scaled, type.est){ 
    nObs = dim(distances$z1)[1]
    # nEval here is the size of the current chunk
    nEval_chunk = dim(distances$z1)[2] 
    d1 = distances$z1
    d2 = distances$z2

    switch(type.est,
        "density" = {
            return(1/(nObs * h^2 * sqrt(detS)) * colSums(K_scaled))
        },
        "NW" = {
            K_scaledY = sweep(K_scaled, 1, Y, "*")
            numerator = colSums(K_scaledY)
            denominator = colSums(K_scaled)
            return(numerator/denominator)
        },
        "LL" = {

            K_scaledY = sweep(K_scaled, 1, Y, "*")
            K_scaled_d1 = K_scaled * d1
            K_scaled_d2 = K_scaled * d2
            
            # Calculate local moments
            S0 = colSums(K_scaled)
            S10 = colSums(K_scaled_d1)
            S20 = colSums(K_scaled_d2)
            S12 = colSums(K_scaled_d1 * d2)
            S11 = colSums(K_scaled * d1^2)
            S22 = colSums(K_scaled * d2^2)
            T0 = colSums(K_scaledY)
            T1 = colSums(K_scaledY * d1)
            T2 = colSums(K_scaledY * d2)
        
            # MDenominator[,,k] is the S_k matrix for the k-th observation IN THE CHUNK
            MDenominator = array(NA,dim=c(3,3,nEval_chunk))
            MDenominator[1,1,] = S0
            MDenominator[1,2,] = S10
            MDenominator[1,3,] = S20
            MDenominator[2,1,] = S10
            MDenominator[2,2,] = S11
            MDenominator[2,3,] = S12
            MDenominator[3,1,] = S20
            MDenominator[3,2,] = S12
            MDenominator[3,3,] = S22
            
            # Keep calculation for solutions (estimator)
            bConstant = rbind(T0,T1,T2)
            solve_system <- function(k) { # k is index within chunk (1 to nEval_chunk)
                if ( det(MDenominator[,,k]) == 0 ) {
                    return(rep(NaN,3))
                }
                
                # SVG GINV
                # A = MDenominator[,,k]
                # svd_A <- svd(A)
                # U <- svd_A$u
                # D <- diag(svd_A$d)
                # V <- svd_A$v
                # 
                # # The singular values show the problem - they get incredibly small
                # # print(svd_A$d)
                # #>  [1] 1.664468e+00 2.871578e-01 2.305413e-02 1.134737e-03 3.655890e-05
                # #>  [6] 7.978254e-07 1.171866e-08 1.116035e-10 6.641618e-13 2.302307e-15
                # 
                # # Compute the pseudoinverse of A by inverting non-tiny singular values
                # # Set a tolerance to avoid dividing by nearly zero
                # tol <- .Machine$double.eps
                # d_inv <- 1 / svd_A$d
                # d_inv[svd_A$d < tol] <- 0 # Crucial step: treat tiny values as zero
                # D_inv <- diag(d_inv)
                # 
                # # A+ = V D+ U'
                # A_pinv <- V %*% D_inv %*% t(U)
                # sol  <- as.numeric(A_pinv %*% bConstant[,k])
                
                # QR
                # A = MDenominator[,,k]
                # sol = as.numeric(solve(qr(A, tol = 1e-32,LAPACK = FALSE), bConstant[,k]))

                # GINV
                # sol = as.numeric(ginv(MDenominator[,,k]) %*% bConstant[,k])
                
                # # RIDGE
                lambda = 1e-5 # small ridge parameter to avoid singularity
                A = MDenominator[,,k]
                sol = as.numeric(solve(A + lambda * diag(3), bConstant[,k]))

                return(sol)
            }
            solutions <- matrix(unlist(purrr::map(1:nEval_chunk, ~ solve_system(.x))),nrow=3,byrow = FALSE)[1,]
            

            calculate_Hkk <- function(k) { # k is index within chunk (1 to nEval_chunk)
                Sk = MDenominator[,,k]
                # Check for singularity
                if ( det(Sk) == 0 ) {
                    return(NaN)
                }
                
                Hkk = ginv(Sk)[1, 1]
                return(Hkk)
            }
            
            # Sum Hkk over the observations in this chunk
            # Note: The condition if (nEval_chunk <= nObs) might not be strictly necessary
            # for the trace calculation itself, unless memory for MDenominator is an issue.
            # AICc is usually calculated when fitting to the original data (nEval=nObs).
            # We compute it regardless, based on the assumption x=X was intended for AICc.
            Hkk_values_chunk <- unlist(purrr::map(1:nEval_chunk, ~ calculate_Hkk(.x))) 
            
            # Return solutions and the vector of Hkk values for this chunk
            return(listN(solutions, Hkk_values_chunk))
        }
    )

}

#' Selects a kernel function based on kernel type
#' 
#' @param kernel.type Type of kernel function ("epa" or "gauss")
#' 
#' @return The corresponding kernel function
defineKernel <- function(kernel.type) {
    if (is.null(kernel.type) || kernel.type == "epa"){ return(epaKernel) }
    else if (kernel.type == "gauss") { return(gaussKernel) } 
    else { stop("kernel not recognized") }
}

#' Epanechnikov kernel function in 2D
#' 
#' @param z1 First dimension standardized distances (nObs x nEval)
#' @param z2 Second dimension standardized distances (nObs x nEval)
#' 
#' @return Kernel weights (nObs x nEval)
epaKernel <- function(z1,z2){
    epaKernel1d(z1)*epaKernel1d(z2)
}

#' Epanechnikov kernel function in 1D
#' 
#' @param z Standardized distances (nObs x nEval)
#' 
#' @return Kernel weights (nObs x nEval)
epaKernel1d <- function(z){
    3/4*(1-z^2)*(abs(z) <= 1)
}

#' Gaussian kernel function in 2D
#' 
#' @param z1 First dimension standardized distances (nObs x nEval)
#' @param z2 Second dimension standardized distances (nObs x nEval)
#' 
#' @return Kernel weights (nObs x nEval)
gaussKernel <- function(z1,z2){
    gaussKernel1d(z1)*gaussKernel1d(z2)
}

#' Gaussian kernel function in 1D
#' 
#' @param z Standardized distances (nObs x nEval)
#' 
#' @return Kernel weights (nObs x nEval)
gaussKernel1d <- function(z){
    1/sqrt(2*pi)*exp(-z^2/2)
}

